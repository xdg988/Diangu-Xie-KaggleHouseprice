{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Price: Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will talk about hyperparameters tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "#from sklearn.metrics import mean_absolute_error\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%store -r X_train\n",
    "%store -r y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-----------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha | \n",
      "    1 | 00m00s | \u001b[35m  -0.01370\u001b[0m | \u001b[32m  85.6168\u001b[0m | \n",
      "    2 | 00m00s | \u001b[35m  -0.01316\u001b[0m | \u001b[32m  32.9363\u001b[0m | \n",
      "    3 | 00m00s |   -0.01358 |   74.5255 | \n",
      "    4 | 00m00s |   -0.01337 |    2.9445 | \n",
      "    5 | 00m00s |   -0.01318 |    4.9909 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m-----------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha | \n",
      "    6 | 00m03s |   -0.01385 |   99.9999 | \n",
      "    7 | 00m04s |   -0.01538 |    0.0135 | \n",
      "    8 | 00m04s |   -0.01385 |   99.9992 | \n",
      "    9 | 00m04s |   -0.01385 |   99.9964 | \n",
      "   10 | 00m04s |   -0.01539 |    0.0101 | \n",
      "   11 | 00m04s |   -0.01385 |   99.9993 | \n",
      "   12 | 00m05s |   -0.01539 |    0.0105 | \n",
      "   13 | 00m05s |   -0.01385 |   99.9969 | \n",
      "   14 | 00m04s |   -0.01385 |   99.9986 | \n",
      "   15 | 00m05s |   -0.01385 |   99.9973 | \n",
      "Final Results\n",
      "Ridge: -0.013158\n"
     ]
    }
   ],
   "source": [
    "def ridgecv(alpha):\n",
    "    val = cross_val_score(Ridge(alpha=alpha), X_train, y_train, 'neg_mean_squared_error', cv=5).mean()\n",
    "    return val\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gp_params = {\"alpha\": 1e-5}\n",
    "\n",
    "    ridgeBO = BayesianOptimization(ridgecv,\n",
    "        {'alpha': (0.01,100)})\n",
    "    #svcBO.explore({'C': [0.001, 0.01, 0.1], 'gamma': [0.001, 0.01, 0.1]}, 'epsilon':[])\n",
    "\n",
    "    ridgeBO.maximize(n_iter=10, **gp_params)\n",
    "#    print('-' * 53)\n",
    "\n",
    "    print('Final Results')\n",
    "    print('Ridge: %f' % ridgeBO.res['max']['max_val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-----------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha | \n",
      "    1 | 00m00s | \u001b[35m  -0.15983\u001b[0m | \u001b[32m   9.7244\u001b[0m | \n",
      "    2 | 00m00s |   -0.15983 |    6.3997 | \n",
      "    3 | 00m00s |   -0.15983 |    9.7198 | \n",
      "    4 | 00m00s |   -0.15983 |    1.8062 | \n",
      "    5 | 00m00s |   -0.15983 |    3.3307 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m-----------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha | \n",
      "    6 | 00m04s | \u001b[35m  -0.01360\u001b[0m | \u001b[32m   0.0015\u001b[0m | \n",
      "    7 | 00m03s | \u001b[35m  -0.01348\u001b[0m | \u001b[32m   0.0001\u001b[0m | \n",
      "    8 | 00m03s |   -0.15983 |    5.9736 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "    9 | 00m04s | \u001b[35m  -0.01348\u001b[0m | \u001b[32m   0.0001\u001b[0m | \n",
      "   10 | 00m04s |   -0.01348 |    0.0001 | \n",
      "   11 | 00m04s |   -0.15983 |    1.2094 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "   12 | 00m04s |   -0.01348 |    0.0001 | \n",
      "   13 | 00m04s |   -0.15983 |    2.4364 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "   14 | 00m06s | \u001b[35m  -0.01348\u001b[0m | \u001b[32m   0.0001\u001b[0m | \n",
      "   15 | 00m04s |   -0.15983 |    2.0423 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "-----------------------------------------------------\n",
      "Final Results\n",
      "Lasso: -0.013481\n"
     ]
    }
   ],
   "source": [
    "def lassocv(alpha):\n",
    "    val = cross_val_score(Lasso(alpha=alpha), X_train, y_train, 'neg_mean_squared_error', cv=5).mean()\n",
    "    return val\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gp_params = {\"alpha\": 1e-5}\n",
    "\n",
    "    lassoBO = BayesianOptimization(lassocv,{'alpha': (0.0001,10)})\n",
    "    #svcBO.explore({'C': [0.001, 0.01, 0.1], 'gamma': [0.001, 0.01, 0.1]}, 'epsilon':[])\n",
    "\n",
    "    lassoBO.maximize(n_iter=10, **gp_params)\n",
    "    print('-' * 53)\n",
    "\n",
    "    print('Final Results')\n",
    "    print('Lasso: %f' % lassoBO.res['max']['max_val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |         C |   epsilon | \n",
      "    1 | 00m01s | \u001b[35m  -0.02198\u001b[0m | \u001b[32m   7.9017\u001b[0m | \u001b[32m   0.0509\u001b[0m | \n",
      "    2 | 00m01s | \u001b[35m  -0.02109\u001b[0m | \u001b[32m   8.7289\u001b[0m | \u001b[32m   0.0314\u001b[0m | \n",
      "    3 | 00m01s | \u001b[35m  -0.01676\u001b[0m | \u001b[32m   1.8644\u001b[0m | \u001b[32m   0.0047\u001b[0m | \n",
      "    4 | 00m01s |   -0.01831 |    3.3337 |    0.0548 | \n",
      "    5 | 00m01s |   -0.01786 |    2.0907 |    0.0781 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |         C |   epsilon | \n",
      "    6 | 00m08s |  -16.43114 |    0.0010 |    0.1000 | \n",
      "    7 | 00m03s |   -0.02116 |    5.5591 |    0.0010 | \n",
      "    8 | 00m02s |   -0.02214 |   10.0000 |    0.1000 | \n",
      "    9 | 00m02s |   -0.02043 |    6.7237 |    0.1000 | \n",
      "   10 | 00m02s |   -0.02205 |    4.4450 |    0.1000 | \n",
      "   11 | 00m02s |   -0.02377 |    9.3748 |    0.0010 | \n",
      "   12 | 00m02s |   -0.02493 |    7.3021 |    0.0010 | \n",
      "   13 | 00m02s |   -0.02270 |    6.1365 |    0.0010 | \n",
      "   14 | 00m03s |   -0.02106 |    3.8915 |    0.0010 | \n",
      "   15 | 00m02s |   -0.01832 |    2.7380 |    0.0010 | \n",
      "-----------------------------------------------------\n",
      "Final Results\n",
      "Linearsvr: -0.016756\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def linearsvrcv(C, epsilon):\n",
    "    val = cross_val_score(LinearSVR(C=C, epsilon=epsilon), X_train, y_train, 'neg_mean_squared_error', cv=5).mean()\n",
    "    return val\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gp_params = {\"alpha\": 1e-5}\n",
    "\n",
    "    linearsvrBO = BayesianOptimization(linearsvrcv,\n",
    "        {'C': (0.001, 10), 'epsilon': (0.001,0.1)})\n",
    "    #svcBO.explore({'C': [0.001, 0.01, 0.1], 'gamma': [0.001, 0.01, 0.1]}, 'epsilon':[])\n",
    "\n",
    "    linearsvrBO.maximize(n_iter=10, **gp_params)\n",
    "    print('-' * 53)\n",
    "\n",
    "    print('Final Results')\n",
    "    print('Linearsvr: %f' % linearsvrBO.res['max']['max_val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |         C |   epsilon |     gamma | \n",
      "    1 | 00m04s | \u001b[35m  -0.03595\u001b[0m | \u001b[32m  59.5270\u001b[0m | \u001b[32m   0.0245\u001b[0m | \u001b[32m   0.0420\u001b[0m | \n",
      "    2 | 00m03s | \u001b[35m  -0.03340\u001b[0m | \u001b[32m  38.3161\u001b[0m | \u001b[32m   0.0260\u001b[0m | \u001b[32m   0.0387\u001b[0m | \n",
      "    3 | 00m02s |   -0.06878 |   16.3971 |    0.0619 |    0.0803 | \n",
      "    4 | 00m03s |   -0.04650 |   53.5253 |    0.0386 |    0.0540 | \n",
      "    5 | 00m02s |   -0.07643 |   22.9545 |    0.0728 |    0.0899 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |         C |   epsilon |     gamma | \n",
      "    6 | 00m10s | \u001b[35m  -0.01255\u001b[0m | \u001b[32m 100.0000\u001b[0m | \u001b[32m   0.0010\u001b[0m | \u001b[32m   0.0001\u001b[0m | \n",
      "    7 | 00m11s |   -0.15953 |    0.0010 |    0.0010 |    0.0001 | \n",
      "    8 | 00m12s |   -0.08497 |   83.7546 |    0.1000 |    0.1000 | \n",
      "    9 | 00m10s |   -0.01264 |   69.5995 |    0.0010 |    0.0001 | \n",
      "   10 | 00m08s |   -0.08497 |   66.8948 |    0.1000 |    0.1000 | \n",
      "   11 | 00m09s |   -0.01261 |   76.5373 |    0.0010 |    0.0001 | \n",
      "   12 | 00m10s |   -0.01257 |   93.4750 |    0.0010 |    0.0001 | \n",
      "   13 | 00m09s |   -0.01415 |    7.8385 |    0.0010 |    0.0001 | \n",
      "   14 | 00m10s |   -0.01296 |   31.5380 |    0.0010 |    0.0001 | \n",
      "   15 | 00m11s |   -0.01279 |   45.3530 |    0.0010 |    0.0001 | \n",
      "-----------------------------------------------------\n",
      "Final Results\n",
      "SVC: -0.012549\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def svccv(C, gamma,epsilon):\n",
    "    val = cross_val_score(SVR(C=C, gamma=gamma, epsilon=epsilon), X_train, y_train, 'neg_mean_squared_error', cv=5).mean()\n",
    "    return val\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gp_params = {\"alpha\": 1e-5}\n",
    "\n",
    "    svcBO = BayesianOptimization(svccv,\n",
    "        {'C': (0.001, 100), 'gamma': (0.0001, 0.1), 'epsilon': (0.001,0.1)})\n",
    "    #svcBO.explore({'C': [0.001, 0.01, 0.1], 'gamma': [0.001, 0.01, 0.1]}, 'epsilon':[])\n",
    "\n",
    "    svcBO.maximize(n_iter=10, **gp_params)\n",
    "    print('-' * 53)\n",
    "\n",
    "    print('Final Results')\n",
    "    print('SVC: %f' % svcBO.res['max']['max_val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   max_features |   min_samples_split |   n_estimators | \n",
      "    1 | 00m08s | \u001b[35m  -0.01891\u001b[0m | \u001b[32m        0.2333\u001b[0m | \u001b[32m            15.9990\u001b[0m | \u001b[32m      243.8621\u001b[0m | \n",
      "    2 | 00m21s |   -0.01976 |         0.8133 |             17.7544 |       239.9131 | \n",
      "    3 | 00m05s |   -0.01929 |         0.1453 |             13.3703 |       235.7054 | \n",
      "    4 | 00m12s | \u001b[35m  -0.01795\u001b[0m | \u001b[32m        0.2469\u001b[0m | \u001b[32m             2.6717\u001b[0m | \u001b[32m      224.8389\u001b[0m | \n",
      "    5 | 00m07s |   -0.01856 |         0.7513 |              5.5903 |        62.5595 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m-------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   max_features |   min_samples_split |   n_estimators | \n",
      "    6 | 00m04s |   -0.02167 |         0.4755 |             23.7129 |        10.0891 | \n",
      "    7 | 00m06s |   -0.02142 |         0.7774 |              3.3929 |        10.0533 | \n",
      "    8 | 00m05s |   -0.02263 |         0.7744 |             24.8918 |        10.0160 | \n",
      "    9 | 00m40s |   -0.01805 |         0.6957 |              2.6142 |       249.9676 | \n",
      "   10 | 00m14s |   -0.01997 |         0.3090 |             24.7054 |       249.9999 | \n",
      "   11 | 00m05s |   -0.02142 |         0.6625 |              2.0655 |        10.0147 | \n",
      "   12 | 00m26s | \u001b[35m  -0.01767\u001b[0m | \u001b[32m        0.3938\u001b[0m | \u001b[32m             2.0289\u001b[0m | \u001b[32m      249.9957\u001b[0m | \n",
      "   13 | 00m22s |   -0.02006 |         0.6222 |             24.3386 |       249.9605 | \n",
      "   14 | 00m05s |   -0.02278 |         0.1648 |             24.6323 |        10.0490 | \n",
      "   15 | 00m43s |   -0.01859 |         0.8673 |              2.3143 |       249.9731 | \n",
      "-----------------------------------------------------\n",
      "RFC: -0.017671\n"
     ]
    }
   ],
   "source": [
    "def rfccv(n_estimators, min_samples_split, max_features):\n",
    "    val = cross_val_score(\n",
    "        RandomForestRegressor(n_estimators=int(n_estimators),\n",
    "            min_samples_split=int(min_samples_split),\n",
    "            max_features=min(max_features, 0.999),\n",
    "        ),\n",
    "        X_train, y_train,  'neg_mean_squared_error', cv=5\n",
    "    ).mean()\n",
    "    return val\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gp_params = {\"alpha\": 1e-5}\n",
    "    \n",
    "    rfcBO = BayesianOptimization(\n",
    "        rfccv,\n",
    "        {'n_estimators': (10, 250),\n",
    "        'min_samples_split': (2, 25),\n",
    "        'max_features': (0.1, 0.999)}\n",
    "    )\n",
    "    rfcBO.maximize(n_iter=10, **gp_params)\n",
    "    print('-' * 53)\n",
    "    print('RFC: %f' % rfcBO.res['max']['max_val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Gradient Boosting Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   max_depth |   max_features |   min_samples_split |   n_estimators | \n",
      "    1 | 00m14s | \u001b[35m  -0.01845\u001b[0m | \u001b[32m   0.4036\u001b[0m | \u001b[32m    10.9911\u001b[0m | \u001b[32m        0.6615\u001b[0m | \u001b[32m             8.9013\u001b[0m | \u001b[32m       69.2425\u001b[0m | \n",
      "    2 | 00m03s | \u001b[35m  -0.01629\u001b[0m | \u001b[32m   0.6725\u001b[0m | \u001b[32m     6.9293\u001b[0m | \u001b[32m        0.4062\u001b[0m | \u001b[32m             8.2079\u001b[0m | \u001b[32m       39.1850\u001b[0m | \n",
      "    3 | 00m04s | \u001b[35m  -0.01530\u001b[0m | \u001b[32m   0.2658\u001b[0m | \u001b[32m     5.5428\u001b[0m | \u001b[32m        0.4956\u001b[0m | \u001b[32m            13.8281\u001b[0m | \u001b[32m       75.1421\u001b[0m | \n",
      "    4 | 00m08s |   -0.01646 |    0.5849 |      7.5647 |         0.6733 |             10.5813 |        65.4436 | \n",
      "    5 | 00m15s | \u001b[35m  -0.01504\u001b[0m | \u001b[32m   0.2637\u001b[0m | \u001b[32m     5.4849\u001b[0m | \u001b[32m        0.8452\u001b[0m | \u001b[32m            13.5505\u001b[0m | \u001b[32m      160.6924\u001b[0m | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   max_depth |   max_features |   min_samples_split |   n_estimators | \n",
      "    6 | 01m10s |   -0.01660 |    0.5473 |     14.5654 |         0.7605 |             24.1117 |       249.9664 | \n",
      "    7 | 00m29s |   -0.01828 |    0.4409 |     12.1630 |         0.4638 |              2.6011 |       249.9419 | \n",
      "    8 | 00m13s |   -0.03889 |    0.1479 |     12.9382 |         0.5630 |             24.5167 |        10.0953 | \n",
      "    9 | 00m17s | \u001b[35m  -0.01432\u001b[0m | \u001b[32m   0.6999\u001b[0m | \u001b[32m     5.0571\u001b[0m | \u001b[32m        0.3671\u001b[0m | \u001b[32m            21.7522\u001b[0m | \u001b[32m      249.6527\u001b[0m | \n",
      "   10 | 00m14s |   -0.01503 |    0.8864 |      5.1211 |         0.2214 |              2.0510 |       154.4863 | \n",
      "   11 | 00m13s |   -0.02742 |    0.6075 |      5.1329 |         0.5846 |              2.0047 |        16.8086 | \n",
      "   12 | 00m22s |   -0.01781 |    0.4039 |     14.9031 |         0.2359 |              2.1373 |       122.8714 | \n",
      "   13 | 00m14s |   -0.01454 |    0.8169 |      5.0064 |         0.1180 |             24.8831 |       163.9525 | \n",
      "   14 | 00m33s |   -0.01532 |    0.9725 |      5.2613 |         0.8357 |              2.4868 |       249.0995 | \n",
      "   15 | 00m24s |   -0.01533 |    0.0781 |      5.0454 |         0.7546 |              2.3436 |       110.7282 | \n",
      "-----------------------------------------------------\n",
      "gbdt: -0.014322\n"
     ]
    }
   ],
   "source": [
    "def gbdtcv(n_estimators, min_samples_split, max_features,alpha,max_depth):\n",
    "    val = cross_val_score(\n",
    "        GradientBoostingRegressor(n_estimators=int(n_estimators),\n",
    "            min_samples_split=int(min_samples_split),\n",
    "            max_features=min(max_features, 0.999),\n",
    "            alpha=max(alpha, 0),\n",
    "            max_depth=int(max_depth)\n",
    "        ),\n",
    "        X_train, y_train,  'neg_mean_squared_error', cv=5\n",
    "    ).mean()\n",
    "    return val\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gp_params = {\"alpha\": 1e-5}\n",
    "    \n",
    "    gbdtBO = BayesianOptimization(\n",
    "        gbdtcv,\n",
    "        {'n_estimators': (10, 250),\n",
    "         'min_samples_split': (2, 25),         \n",
    "         'max_features': (0.1, 0.999),\n",
    "         'alpha': (0, 0.9999),\n",
    "         'max_depth': (5, 15),\n",
    "        }\n",
    "    )\n",
    "    gbdtBO.maximize(n_iter=10, **gp_params)\n",
    "    print('-' * 53)\n",
    "    print('gbdt: %f' % gbdtBO.res['max']['max_val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   reg_alpha |   subsample | \n",
      "    1 | 00m03s | \u001b[35m  -0.03220\u001b[0m | \u001b[32m            0.7897\u001b[0m | \u001b[32m   1.9093\u001b[0m | \u001b[32m     5.7198\u001b[0m | \u001b[32m           13.3867\u001b[0m | \u001b[32m     4.7518\u001b[0m | \u001b[32m     0.6805\u001b[0m | \n",
      "    2 | 00m01s |   -0.03828 |             0.5100 |    3.1551 |      5.4087 |            10.2477 |      6.0825 |      0.7690 | \n",
      "    3 | 00m02s | \u001b[35m  -0.02845\u001b[0m | \u001b[32m            0.5899\u001b[0m | \u001b[32m   1.2265\u001b[0m | \u001b[32m     8.0970\u001b[0m | \u001b[32m           12.0785\u001b[0m | \u001b[32m     6.4681\u001b[0m | \u001b[32m     0.8795\u001b[0m | \n",
      "    4 | 00m02s | \u001b[35m  -0.02630\u001b[0m | \u001b[32m            0.3874\u001b[0m | \u001b[32m   1.0782\u001b[0m | \u001b[32m    14.6929\u001b[0m | \u001b[32m            3.6300\u001b[0m | \u001b[32m     1.5642\u001b[0m | \u001b[32m     0.5364\u001b[0m | \n",
      "    5 | 00m02s |   -0.05463 |             0.4790 |    6.1897 |     12.4351 |             3.1605 |      5.1567 |      0.5640 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   reg_alpha |   subsample | \n",
      "    6 | 00m18s | \u001b[35m  -0.02526\u001b[0m | \u001b[32m            0.7153\u001b[0m | \u001b[32m   0.0709\u001b[0m | \u001b[32m     6.2201\u001b[0m | \u001b[32m            1.1166\u001b[0m | \u001b[32m     9.2813\u001b[0m | \u001b[32m     0.5772\u001b[0m | \n",
      "    7 | 00m32s | \u001b[35m  -0.01727\u001b[0m | \u001b[32m            0.2635\u001b[0m | \u001b[32m   0.0072\u001b[0m | \u001b[32m    14.6989\u001b[0m | \u001b[32m           19.8979\u001b[0m | \u001b[32m     2.0321\u001b[0m | \u001b[32m     0.6632\u001b[0m | \n",
      "    8 | 00m26s | \u001b[35m  -0.01427\u001b[0m | \u001b[32m            0.3502\u001b[0m | \u001b[32m   0.0455\u001b[0m | \u001b[32m     5.9185\u001b[0m | \u001b[32m           19.2828\u001b[0m | \u001b[32m     0.0307\u001b[0m | \u001b[32m     0.9616\u001b[0m | \n",
      "    9 | 00m29s |   -0.01453 |             0.1892 |    0.0240 |      5.6611 |             2.2415 |      0.2816 |      0.8514 | \n",
      "   10 | 00m26s |   -0.01516 |             0.2025 |    0.0082 |      7.6239 |            14.3109 |      0.2511 |      0.9992 | \n",
      "   11 | 00m23s |   -0.01598 |             0.1306 |    0.1009 |      6.5311 |            19.7776 |      0.0725 |      0.9813 | \n",
      "   12 | 00m32s |   -0.01579 |             0.9932 |    0.0884 |     13.9114 |            11.8126 |      0.3447 |      0.9783 | \n",
      "   13 | 00m23s |   -0.02278 |             0.2910 |    0.0942 |     14.9515 |             7.0554 |      9.4466 |      0.8931 | \n",
      "   14 | 00m26s |   -0.02448 |             0.2049 |    0.0741 |      6.0969 |            19.3184 |      9.9420 |      0.7820 | \n",
      "   15 | 00m27s |   -0.01579 |             0.9338 |    0.0856 |      5.7767 |            11.4037 |      0.1906 |      0.5167 | \n",
      "   16 | 00m26s |   -0.01535 |             0.4385 |    0.0330 |      5.2898 |             8.7556 |      0.6757 |      0.9639 | \n",
      "   17 | 00m34s |   -0.02483 |             0.8702 |    0.3738 |     14.1024 |            19.3122 |      9.6737 |      0.9612 | \n",
      "   18 | 00m42s |   -0.01710 |             0.9471 |    0.2303 |     14.6081 |            19.7539 |      0.1647 |      0.6935 | \n",
      "   19 | 00m26s |   -0.01492 |             0.5303 |    0.0009 |      5.0462 |            16.4244 |      0.0913 |      0.6776 | \n",
      "   20 | 00m30s |   -0.01515 |             0.2308 |    0.0009 |     14.2322 |             1.2162 |      0.1681 |      0.9718 | \n",
      "   21 | 00m30s |   -0.01539 |             0.7992 |    0.0009 |     10.1496 |             2.1858 |      0.3593 |      0.9378 | \n",
      "   22 | 00m29s |   -0.01558 |             0.8532 |    0.0374 |      8.1473 |            17.7978 |      0.6336 |      0.9575 | \n",
      "   23 | 00m29s |   -0.01800 |             0.8679 |    0.2484 |      5.9007 |             1.3858 |      0.4357 |      0.9407 | \n",
      "   24 | 00m30s |   -0.01579 |             0.1363 |    0.0620 |     10.8879 |             8.2671 |      0.1657 |      0.8505 | \n",
      "   25 | 00m28s |   -0.02027 |             0.1072 |    0.0353 |      9.7635 |             1.1482 |      3.6088 |      0.6764 | \n",
      "   26 | 00m29s |   -0.01479 |             0.5689 |    0.0146 |      5.6624 |            19.7668 |      0.1036 |      0.9173 | \n",
      "   27 | 00m29s |   -0.05885 |             0.9713 |    9.9136 |     14.9519 |            19.2496 |      9.6549 |      0.8905 | \n",
      "   28 | 00m28s |   -0.05239 |             0.3155 |    9.8181 |      5.0023 |            16.0452 |      0.0347 |      0.9207 | \n",
      "   29 | 00m35s |   -0.02584 |             0.3915 |    0.1490 |     14.4639 |             1.3536 |      9.6227 |      0.5663 | \n",
      "   30 | 00m30s |   -0.01622 |             0.1484 |    0.0527 |     14.6819 |            15.1454 |      0.4468 |      0.6188 | \n",
      "Final Results\n",
      "xgb: -0.014271\n",
      "{'min_child_weight': 19.282777672545986, 'colsample_bytree': 0.35016721994439359, 'max_depth': 5.9184602923516358, 'subsample': 0.9616424405602666, 'gamma': 0.045470231097461955, 'reg_alpha': 0.030661636572545392}\n"
     ]
    }
   ],
   "source": [
    "X=X_train\n",
    "y=y_train\n",
    "\n",
    "def xgb_evaluate(min_child_weight,\n",
    "                 colsample_bytree,\n",
    "                 max_depth,\n",
    "                 subsample,\n",
    "                 gamma,\n",
    "                 reg_alpha):\n",
    "\n",
    "\n",
    "    cv_result = cross_val_score(XGBRegressor(min_child_weight= int(min_child_weight),\n",
    "                                            colsample_bytree=max(min(colsample_bytree, 1), 0),\n",
    "                                            max_depth=int(max_depth),\n",
    "                                            subsample=max(min(subsample, 1), 0),\n",
    "                                            gamma=max(gamma, 0),\n",
    "                                            reg_alpha = max(reg_alpha, 0)\n",
    "                                            ),\n",
    "                                X, y, 'neg_mean_squared_error', cv=5).mean()\n",
    "    return cv_result\n",
    "\n",
    "\n",
    "num_iter = 25\n",
    "init_points = 5\n",
    "\n",
    "xgbBO = BayesianOptimization(xgb_evaluate, {'min_child_weight': (1, 20),\n",
    "                                                'colsample_bytree': (0.1, 1),\n",
    "                                                'max_depth': (5, 15),\n",
    "                                                'subsample': (0.5, 1),\n",
    "                                                'gamma': (0, 10),\n",
    "                                                'reg_alpha': (0, 10),\n",
    "                                                })\n",
    "\n",
    "xgbBO.maximize(init_points=init_points, n_iter=num_iter)\n",
    "\n",
    "print('Final Results')\n",
    "print('xgb: %f' % xgbBO.res['max']['max_val'])\n",
    "print(xgbBO.res['max']['max_params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |   min_child_weight |   min_split_gain |   num_leaves |   reg_alpha |   subsample | \n",
      "    1 | 00m00s | \u001b[35m  -0.05919\u001b[0m | \u001b[32m            0.9191\u001b[0m | \u001b[32m            4.2369\u001b[0m | \u001b[32m          7.5436\u001b[0m | \u001b[32m    193.6326\u001b[0m | \u001b[32m     3.5613\u001b[0m | \u001b[32m     0.7575\u001b[0m | \n",
      "    2 | 00m00s |   -0.06659 |             0.2970 |             4.3337 |           5.2283 |     495.5037 |      7.2383 |      0.5462 | \n",
      "    3 | 00m00s | \u001b[35m  -0.05848\u001b[0m | \u001b[32m            0.8704\u001b[0m | \u001b[32m            8.8431\u001b[0m | \u001b[32m          9.8121\u001b[0m | \u001b[32m    137.7831\u001b[0m | \u001b[32m     2.2188\u001b[0m | \u001b[32m     0.9050\u001b[0m | \n",
      "    4 | 00m00s | \u001b[35m  -0.04078\u001b[0m | \u001b[32m            0.8276\u001b[0m | \u001b[32m            7.2853\u001b[0m | \u001b[32m          1.4498\u001b[0m | \u001b[32m     65.2624\u001b[0m | \u001b[32m     9.1423\u001b[0m | \u001b[32m     0.7585\u001b[0m | \n",
      "    5 | 00m00s |   -0.05381 |             0.5886 |             6.9901 |           4.7779 |     102.5887 |      9.8985 |      0.8825 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m-------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |   min_child_weight |   min_split_gain |   num_leaves |   reg_alpha |   subsample | \n",
      "    6 | 00m13s | \u001b[35m  -0.01598\u001b[0m | \u001b[32m            0.1000\u001b[0m | \u001b[32m            0.0000\u001b[0m | \u001b[32m          0.0000\u001b[0m | \u001b[32m   1024.0000\u001b[0m | \u001b[32m     0.0000\u001b[0m | \u001b[32m     0.5000\u001b[0m | \n",
      "    7 | 00m11s |   -0.02169 |             0.7411 |             0.7676 |           0.7237 |     831.6167 |      0.0695 |      0.8278 | \n",
      "    8 | 00m14s |   -0.04722 |             0.9797 |             0.1387 |           7.2619 |      10.8288 |      0.0385 |      0.9352 | \n",
      "    9 | 00m12s |   -0.03501 |             0.2697 |             9.8410 |           1.1499 |     936.6429 |      9.2863 |      0.9269 | \n",
      "   10 | 00m11s | \u001b[35m  -0.01564\u001b[0m | \u001b[32m            0.4687\u001b[0m | \u001b[32m            9.6990\u001b[0m | \u001b[32m          0.0465\u001b[0m | \u001b[32m    713.0053\u001b[0m | \u001b[32m     0.6464\u001b[0m | \u001b[32m     0.6421\u001b[0m | \n",
      "   11 | 00m14s |   -0.05127 |             0.7737 |             8.5598 |           8.4485 |    1020.5771 |      0.1292 |      0.8877 | \n",
      "   12 | 00m10s |   -0.02972 |             0.1681 |             0.4986 |           0.2836 |     742.2693 |      9.9748 |      0.9861 | \n",
      "   13 | 00m17s |   -0.01806 |             0.9881 |             1.3892 |           0.1840 |     646.9974 |      0.3381 |      0.7787 | \n",
      "   14 | 00m22s |   -0.02094 |             0.4102 |             0.6270 |           0.4676 |     952.5130 |      0.5039 |      0.5300 | \n",
      "   15 | 00m22s | \u001b[35m  -0.01505\u001b[0m | \u001b[32m            0.2453\u001b[0m | \u001b[32m            0.0000\u001b[0m | \u001b[32m          0.0000\u001b[0m | \u001b[32m     78.8437\u001b[0m | \u001b[32m     0.0000\u001b[0m | \u001b[32m     0.5000\u001b[0m | \n",
      "   16 | 00m23s |   -0.01611 |             0.7812 |             1.3471 |           0.0813 |     706.4315 |      0.0586 |      0.9394 | \n",
      "   17 | 00m24s |   -0.01533 |             0.6365 |             8.3551 |           0.0106 |     123.1902 |      0.4486 |      0.8241 | \n",
      "   18 | 00m21s | \u001b[35m  -0.01498\u001b[0m | \u001b[32m            0.2912\u001b[0m | \u001b[32m            9.9311\u001b[0m | \u001b[32m          0.0469\u001b[0m | \u001b[32m    656.6155\u001b[0m | \u001b[32m     0.2133\u001b[0m | \u001b[32m     0.8414\u001b[0m | \n",
      "   19 | 00m20s |   -0.01602 |             0.7459 |             9.0814 |           0.0444 |      81.9495 |      0.0304 |      0.9612 | \n",
      "   20 | 00m20s |   -0.01768 |             0.9757 |             0.9350 |           0.1709 |     124.1002 |      0.0228 |      0.9483 | \n",
      "   21 | 00m20s |   -0.01697 |             0.1208 |             3.8230 |           0.1081 |     703.0774 |      0.1046 |      0.5409 | \n",
      "   22 | 00m23s | \u001b[35m  -0.01475\u001b[0m | \u001b[32m            0.6885\u001b[0m | \u001b[32m            9.7185\u001b[0m | \u001b[32m          0.0042\u001b[0m | \u001b[32m    327.6038\u001b[0m | \u001b[32m     0.3788\u001b[0m | \u001b[32m     0.6977\u001b[0m | \n",
      "   23 | 00m21s |   -0.01897 |             0.3516 |             9.9944 |           0.3167 |     393.0910 |      0.3682 |      0.8493 | \n",
      "   24 | 00m23s |   -0.01576 |             0.3364 |             9.5370 |           0.0870 |     563.0804 |      0.0432 |      0.9480 | \n",
      "   25 | 00m22s |   -0.01571 |             0.8228 |             4.0934 |           0.0628 |     774.4661 |      0.0218 |      0.9399 | \n",
      "   26 | 00m21s |   -0.01618 |             0.8828 |             9.6254 |           0.0497 |     270.8455 |      0.5596 |      0.5402 | \n",
      "   27 | 00m21s |   -0.01528 |             0.6837 |             9.9061 |           0.0362 |    1022.2218 |      0.4190 |      0.7383 | \n",
      "   28 | 00m21s |   -0.01595 |             0.7468 |             1.6875 |           0.0447 |    1004.3071 |      0.3231 |      0.8765 | \n",
      "   29 | 00m20s |   -0.01644 |             0.3630 |             9.3979 |           0.1219 |     609.8952 |      0.2270 |      0.6212 | \n",
      "   30 | 00m23s |   -0.01659 |             0.3917 |             8.4302 |           0.1618 |     172.4497 |      0.0677 |      0.9664 | \n",
      "Final Results\n",
      "lgb: -0.014753\n",
      "{'min_child_weight': 9.718522121244936, 'colsample_bytree': 0.68853759092982225, 'num_leaves': 327.60379454575576, 'subsample': 0.6977070021528049, 'min_split_gain': 0.0041930506910459187, 'reg_alpha': 0.37884336522993611}\n"
     ]
    }
   ],
   "source": [
    "def lgb_evaluate(min_child_weight,\n",
    "                 colsample_bytree,\n",
    "                 num_leaves,\n",
    "                 subsample,\n",
    "                 min_split_gain,\n",
    "                 reg_alpha):\n",
    "\n",
    "\n",
    "    cv_result = cross_val_score(LGBMRegressor(min_child_weight= int(min_child_weight),\n",
    "                                            colsample_bytree=max(min(colsample_bytree, 1), 0),\n",
    "                                            num_leaves=int(num_leaves),\n",
    "                                            subsample=max(min(subsample, 1), 0),\n",
    "                                            min_split_gain=max(min_split_gain, 0),\n",
    "                                            reg_alpha = max(reg_alpha, 0)\n",
    "                                            ),\n",
    "                                X_train, y_train, 'neg_mean_squared_error', cv=5).mean()\n",
    "    return cv_result\n",
    "\n",
    "\n",
    "num_iter = 25\n",
    "init_points = 5\n",
    "\n",
    "lgbBO = BayesianOptimization(lgb_evaluate, {'min_child_weight': (0, 10),\n",
    "                                                'colsample_bytree': (0.1, 1),\n",
    "                                                'num_leaves': (8, 1024),\n",
    "                                                'subsample': (0.5, 1),\n",
    "                                                'min_split_gain': (0, 10),\n",
    "                                                'reg_alpha': (0, 10),\n",
    "                                                })\n",
    "\n",
    "lgbBO.maximize(init_points=init_points, n_iter=num_iter)\n",
    "\n",
    "print('Final Results')\n",
    "print('lgb: %f' % lgbBO.res['max']['max_val'])\n",
    "print(lgbBO.res['max']['max_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
